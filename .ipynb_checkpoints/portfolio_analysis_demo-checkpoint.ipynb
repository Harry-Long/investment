{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf74e722",
   "metadata": {},
   "source": [
    "\n",
    "# Portfolio Analysis Demo (QuantStats + PyPortfolioOpt)\n",
    "\n",
    "This notebook is a minimal, offline-ready demo that shows how to:\n",
    "- Generate synthetic price data for a few tickers\n",
    "- Compute returns and basic risk metrics\n",
    "- Create a quick performance summary with **QuantStats**\n",
    "- Optimize weights with **PyPortfolioOpt** (mean-variance example)\n",
    "- Plot equity curve and risk contributions\n",
    "\n",
    "> Run this inside your `invest` conda environment:\n",
    ">\n",
    "> ```bash\n",
    "> conda activate invest\n",
    "> jupyter lab\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Versions and imports\n",
    "import sys, platform\n",
    "print('Python:', sys.version.split()[0], '| Platform:', platform.platform())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# QuantStats and PyPortfolioOpt\n",
    "import quantstats as qs\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier, objective_functions\n",
    "\n",
    "# Make plots inline if in Jupyter\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c6437",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Generate synthetic price data\n",
    "We simulate daily prices for 4 tickers over ~2 years of business days. This avoids any external data dependency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-03', periods=252*2, freq='B')\n",
    "tickers = ['VTI','VXUS','BND','BIL']\n",
    "\n",
    "# annualized drifts and vols (illustrative only)\n",
    "mu_ann = np.array([0.08, 0.07, 0.03, 0.02])\n",
    "vol_ann = np.array([0.18, 0.20, 0.06, 0.01])\n",
    "\n",
    "mu_d = mu_ann / 252.0\n",
    "vol_d = vol_ann / np.sqrt(252.0)\n",
    "\n",
    "prices = pd.DataFrame(index=dates, columns=tickers, dtype=float)\n",
    "prices.iloc[0] = [200.0, 60.0, 75.0, 100.0]\n",
    "for t in range(1, len(dates)):\n",
    "    shock = np.random.normal(0, vol_d)\n",
    "    prices.iloc[t] = prices.iloc[t-1] * (1 + mu_d + shock)\n",
    "\n",
    "prices.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688fd2b",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Compute returns and basic metrics\n",
    "We will use log returns for aggregation and transform to arithmetic returns for some libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ff331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logret = np.log(prices).diff().dropna()\n",
    "ret = logret.apply(np.exp) - 1.0  # convert to simple returns\n",
    "ret.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1647b6",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Quick performance summary with QuantStats\n",
    "QuantStats can compute a variety of metrics and plots. We will build a simple **portfolio** using naive 60/20/18/2 weights and view the metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176733e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import quantstats as qs\n",
    "w = pd.Series({'VTI':0.60,'VXUS':0.20,'BND':0.18,'BIL':0.02})\n",
    "w = w / w.sum()\n",
    "\n",
    "# portfolio daily returns (weighted sum of component returns)\n",
    "pf_ret = (ret * w).sum(axis=1)\n",
    "\n",
    "# Basic stats table\n",
    "qs.reports.metrics(pf_ret, display=True, mode='basic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cb95f",
   "metadata": {},
   "source": [
    "\n",
    "### Equity curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nav = (1 + pf_ret).cumprod()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(nav.index, nav.values)\n",
    "plt.title('Portfolio Net Asset Value (Synthetic)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('NAV')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0fd3b",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Optimize weights with PyPortfolioOpt\n",
    "We use mean-variance optimization with a target of maximizing the Sharpe ratio, along with an L2 regularization term to avoid extreme weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e42895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier, objective_functions\n",
    "\n",
    "mu = expected_returns.mean_historical_return(prices, frequency=252)  # expected annual return\n",
    "S = risk_models.sample_cov(prices, frequency=252)                    # annualized covariance\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.add_objective(objective_functions.L2_reg, gamma=0.001)\n",
    "opt_w = ef.max_sharpe(risk_free_rate=0.0)\n",
    "clean_w = ef.clean_weights()\n",
    "perf = ef.portfolio_performance(verbose=True, risk_free_rate=0.0)\n",
    "\n",
    "clean_w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621c8e8",
   "metadata": {},
   "source": [
    "\n",
    "### Risk contributions (from covariance and optimized weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb62563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def annualized_cov(returns: pd.DataFrame, periods_per_year=252) -> pd.DataFrame:\n",
    "    return returns.cov() * periods_per_year\n",
    "\n",
    "def portfolio_volatility(w: pd.Series, cov: pd.DataFrame) -> float:\n",
    "    w = w.values if isinstance(w, pd.Series) else np.asarray(w)\n",
    "    v = float(np.sqrt(max(w @ cov.values @ w, 0.0)))\n",
    "    return v\n",
    "\n",
    "def risk_contribution(w: pd.Series, cov: pd.DataFrame) -> pd.Series:\n",
    "    wv = pd.Series(w, index=cov.index)\n",
    "    total_vol = portfolio_volatility(wv, cov)\n",
    "    mrc = cov @ wv  # marginal risk contribution\n",
    "    rc = wv * mrc / total_vol\n",
    "    return rc\n",
    "\n",
    "cov_a = annualized_cov(ret)\n",
    "opt_w_series = pd.Series(clean_w).reindex(cov_a.index).fillna(0.0)\n",
    "rc = risk_contribution(opt_w_series, cov_a).sort_values(ascending=False)\n",
    "rc.to_frame('RiskContribution')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6aa2c",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Value-at-Risk (VaR) and Expected Shortfall (ES)\n",
    "Historical method on portfolio daily returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd49b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def var_es_hist(ret_series: pd.Series, alpha=0.95):\n",
    "    q = ret_series.quantile(1 - alpha)\n",
    "    es = ret_series[ret_series <= q].mean()\n",
    "    return {\"VaR\": float(q), \"ES\": float(es)}\n",
    "\n",
    "# Use optimized weights to form portfolio returns\n",
    "pf_ret_opt = (ret * opt_w_series.reindex(ret.columns).fillna(0.0)).sum(axis=1)\n",
    "risk_95 = var_es_hist(pf_ret_opt, alpha=0.95)\n",
    "risk_99 = var_es_hist(pf_ret_opt, alpha=0.99)\n",
    "risk_95, risk_99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c452f",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Wrap up\n",
    "You now have:\n",
    "- Synthetic prices and returns\n",
    "- A quick QuantStats summary\n",
    "- Mean-variance optimized weights from PyPortfolioOpt\n",
    "- Risk contributions and VaR/ES estimates\n",
    "\n",
    "Next steps you can try:\n",
    "- Swap synthetic data for your real data source\n",
    "- Add transaction costs and turnover constraints in the optimizer\n",
    "- Run scenario replays and drawdown analyses for stress testing\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
